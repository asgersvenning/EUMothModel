{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for developing the QC pipeline\n",
    "## Setup\n",
    "### User parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"qualityControlV1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /home/ucloud/EUMothModel\n"
     ]
    }
   ],
   "source": [
    "import os, sys, pathlib, time, random\n",
    "# Move working directory to the root of the project\n",
    "os.chdir(\"/home/ucloud/EUMothModel\")\n",
    "print(\"Working directory:\", os.getcwd())\n",
    "\n",
    "# __package__ = \"..\"\n",
    "# sys.path.append(os.path.abspath(__package__))\n",
    "\n",
    "# from rclonemountpy.utils.mount import *\n",
    "from utils.implicit_mount import *\n",
    "from utils.dataloader import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda detection & Datatype selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to sftp://asgersvenning%40ecos.au.dk@io.erda.au.dk:2222\n",
      "Local directory: /tmp/tmpzot0lq87\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade5fc41391048cd88518dafa1155692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up...\n"
     ]
    }
   ],
   "source": [
    "with IOHandler(verbose = False) as mount:\n",
    "    mount.cd(\"AMI_GBIF_Pretraining_Data/root\")\n",
    "\n",
    "    mount.cache_file_index(skip = 1000, nmax = 128*10)\n",
    "\n",
    "    total_size = 0\n",
    "\n",
    "    pbar = tqdm(enumerate(RemotePathIterator(mount, batch_size=128, n_local_files=128*3)), total = 128*10, leave = False)\n",
    "    start_time = time.time()\n",
    "\n",
    "    batch = []\n",
    "    for i, (l_file, r_file),  in pbar:\n",
    "        batch += [l_file]\n",
    "        if len(batch) == 128:\n",
    "            for file in batch:\n",
    "                file_size = os.path.getsize(file)\n",
    "                total_size += file_size\n",
    "                elapsed_time = time.time() - start_time\n",
    "                pbar.set_description(f\"Total size: {total_size / 1e6:.2f} MB | Elapsed time: {elapsed_time:.2f} s | Speed: {(total_size / elapsed_time) / 1e6:.2f} MB/s\")\n",
    "            batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = IOHandler(verbose = False)\n",
    "backend.cd(\"AMI_GBIF_Pretraining_Data/root\")\n",
    "backend.cache_file_index(skip = 1000, nmax = 128*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_V2_S_Weights.DEFAULT\n",
    "image_preprocessing = weights.transforms(antialias=True)\n",
    "def denormalize(tensor, mean=image_preprocessing.mean, std=image_preprocessing.std):\n",
    "    \"\"\"Denormalize a tensor.\"\"\"\n",
    "    mean = torch.tensor(mean).view(1, 3, 1, 1).to(torch.float32)\n",
    "    std = torch.tensor(std).view(1, 3, 1, 1).to(torch.float32)\n",
    "    return tensor.cpu().to(torch.float32) * std + mean\n",
    "\n",
    "dataset = RemotePathDataset(\n",
    "    remote_path_iterator=RemotePathIterator(\n",
    "        backend,\n",
    "        batch_size=128,\n",
    "        n_local_files=128*3,\n",
    "    ),\n",
    "    transform=image_preprocessing\n",
    ")\n",
    "dataloader = CustomDataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input, label in tqdm(dataloader, leave = True):\n",
    "    print(input.shape, label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model import\n",
    "The model has been trained on a small hand-annotated dataset. Unfortunately this is currently a quite messy workflow, since it is done it Google Colab and not on uCloud, where the rest of the processing will be done. This will be fixed later and is an issue of asyncronous software and infrastructure development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: efficientnet_v2_s\n",
    "model = torchvision.models.efficientnet_v2_s(weights = weights).train(False).half()\n",
    "num_features = [k for k in [j for j in [i for i in model.children()][0].children()][-1].children()][0].out_channels\n",
    "num_classes = 3\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.BatchNorm1d(num_features),\n",
    "    nn.Linear(num_features, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(512, num_classes),\n",
    ")\n",
    "model.load_state_dict(torch.load(\"models/{model_name}.pt\"))\n",
    "model = model.to(device=device, dtype=dtype)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedEfficientNet(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(EmbedEfficientNet, self).__init__()\n",
    "\n",
    "        children = list(original_model.children())\n",
    "\n",
    "        # Extract all layers except the classifier\n",
    "        self.features = nn.Sequential(*children)[:-1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        return x\n",
    "\n",
    "embeddings_model = EmbedEfficientNet(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, images, embeddings = [], [], []\n",
    "\n",
    "# inference loop\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(dataloader):\n",
    "        inputs = inputs.to(device=device, dtype=dtype)\n",
    "        scores = model(inputs)\n",
    "        embeddings.append(embeddings_model(inputs).float().cpu().numpy())\n",
    "        preds = scores.float().exp()\n",
    "        preds /= preds.sum(dim=1, keepdim=True)\n",
    "        predictions.append(preds.cpu().numpy())\n",
    "        images.append(denormalize(inputs).cpu().numpy())\n",
    "\n",
    "predictions = np.concatenate(predictions)\n",
    "images = np.concatenate(images)\n",
    "embeddings = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions \n",
    "fig, ax = plt.subplots(34, 3, figsize=(15, 100))\n",
    "\n",
    "for i in range(100):\n",
    "    this_row = images[i].transpose(1,2,0)\n",
    "    # clamp\n",
    "    this_row = np.clip(this_row, 0, 1)\n",
    "    ax[i//3, i%3].imshow(this_row)\n",
    "    ax[i//3, i%3].set_title(f\"Prediction: {predictions[i][0]:.0%} {predictions[i][1]:.0%} {predictions[i][2]:.0%}\")\n",
    "    ax[i//3, i%3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_normalized = torch.tensor(embeddings)\n",
    "embeddings_normalized /= embeddings_normalized.norm(dim=1, keepdim=True)\n",
    "plt.scatter(*torch.pca_lowrank(embeddings_normalized, q=2)[0].numpy().transpose())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
