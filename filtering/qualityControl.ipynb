{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for developing the QC pipeline\n",
    "## Setup\n",
    "### User parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"qualityControlV1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /home/ucloud/EUMothModel\n"
     ]
    }
   ],
   "source": [
    "import os, sys, pathlib, time, random\n",
    "# Move working directory to the root of the project\n",
    "os.chdir(\"/home/ucloud/EUMothModel\")\n",
    "print(\"Working directory:\", os.getcwd())\n",
    "\n",
    "# __package__ = \"..\"\n",
    "# sys.path.append(os.path.abspath(__package__))\n",
    "\n",
    "# from rclonemountpy.utils.mount import *\n",
    "from utils.implicit_mount import *\n",
    "from utils.dataloader import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda detection & Datatype selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to sftp://asgersvenning%40ecos.au.dk:@io.erda.au.dk:2222\n",
      "Local directory: /tmp/tmpo7y7374m\n",
      "IOHandler.start() is unsafe. Use IOHandler.__enter__() instead if possible.\n",
      "OBS: Remember to call IOHandler.stop() when you are done.\n"
     ]
    }
   ],
   "source": [
    "if backend is not None:\n",
    "    backend.stop()\n",
    "backend = IOHandler(verbose = False, clean=True)\n",
    "backend.start()\n",
    "backend.cd(\"AMI_GBIF_Pretraining_Data/root\")\n",
    "backend.cache_file_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_V2_S_Weights.DEFAULT\n",
    "image_preprocessing = weights.transforms(antialias=True)\n",
    "def denormalize(tensor, mean=image_preprocessing.mean, std=image_preprocessing.std):\n",
    "    \"\"\"Denormalize a tensor.\"\"\"\n",
    "    mean = torch.tensor(mean).view(1, 3, 1, 1).to(torch.float32)\n",
    "    std = torch.tensor(std).view(1, 3, 1, 1).to(torch.float32)\n",
    "    return tensor.cpu().to(torch.float32) * std + mean\n",
    "\n",
    "dataset = RemotePathDataset(\n",
    "    remote_path_iterator=RemotePathIterator(\n",
    "        backend,\n",
    "        batch_size=128,\n",
    "        max_queued_batches=5,\n",
    "        n_local_files=2*128*5\n",
    "    ),\n",
    "    prefetch=4*32,\n",
    "    transform=image_preprocessing,\n",
    "    device=device,\n",
    "    dtype=dtype,\n",
    "    return_remote_path=True\n",
    ")\n",
    "dataloader = CustomDataLoader(dataset=dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model import\n",
    "The model has been trained on a small hand-annotated dataset. Unfortunately this is currently a quite messy workflow, since it is done it Google Colab and not on uCloud, where the rest of the processing will be done. This will be fixed later and is an issue of asyncronous software and infrastructure development.\n",
    "\n",
    "Once images have passed QC the images can be moved to an appropriate directory, while maintaining the proper subdirectory structure with:\n",
    "```lftp\n",
    "mget -d -O sftp://io.erda.au.dk:/AMI_GBIF_Pretraining_Data/NEW_SUPER_DIRECTORY ./PATH_TO_IMAGE\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QC_dict = {\n",
    "    0 : \"Larvae\",\n",
    "    1 : \"Low\",\n",
    "    2 : \"High\"\n",
    "}\n",
    "\n",
    "# model: efficientnet_v2_s\n",
    "model = torchvision.models.efficientnet_v2_s(weights = weights).train(False).half()\n",
    "num_features = [k for k in [j for j in [i for i in model.children()][0].children()][-1].children()][0].out_channels\n",
    "num_classes = 3\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.BatchNorm1d(num_features),\n",
    "    nn.Linear(num_features, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(512, num_classes),\n",
    ")\n",
    "model.load_state_dict(torch.load(f\"models/{model_name}.pt\"))\n",
    "model = model.to(device=device, dtype=dtype)\n",
    "model = model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an inference test collage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# many_inputs = []\n",
    "\n",
    "# for i, (input, label, path) in tqdm(enumerate(dataloader), leave = True):\n",
    "#     many_inputs.append(input)\n",
    "#     if i == 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Preparing\")\n",
    "\n",
    "# probs_max_l = []\n",
    "# inf_cls_l = []\n",
    "# inf_cls_name_l = []\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# print(\"Inference started...\")\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for input in tqdm(many_inputs, leave = False):\n",
    "#         logits = model(input)\n",
    "#         probs = F.softmax(logits, dim=1)\n",
    "\n",
    "#         inf_cls, probs_max = probs.argmax(dim=1), probs.max(dim=1).values\n",
    "#         inf_cls, probs_max = inf_cls.cpu(), probs_max.cpu().float()\n",
    "\n",
    "#         inf_cls_name = [QC_dict[i.item()] for i in inf_cls]\n",
    "\n",
    "#         probs_max_l.append(probs_max)\n",
    "#         inf_cls_l.append(inf_cls)\n",
    "#         inf_cls_name_l.append(inf_cls_name)\n",
    "\n",
    "# probs_max = torch.cat(probs_max_l, dim=0)\n",
    "# inf_cls = torch.cat(inf_cls_l, dim=0)\n",
    "# inf_cls_name = [i for j in inf_cls_name_l for i in j]\n",
    "\n",
    "# print(\"Inference done!\")\n",
    "\n",
    "# ## Subset of 900 random images from the dataset and sort them by their predicted class\n",
    "# # Generate 900 random indices, ensuring they're within the bounds of the dataset\n",
    "# random_indices = torch.randperm(len(inf_cls))[:900]\n",
    "\n",
    "# # Sort the random subset by the predicted class\n",
    "# idx_sort_subset = torch.argsort(inf_cls[random_indices])\n",
    "\n",
    "# # Map sorted indices back to the original dataset\n",
    "# idx_sort = random_indices[idx_sort_subset]\n",
    "\n",
    "# imgs = torch.concat([i.cpu() for i in many_inputs], dim=0)[idx_sort]\n",
    "# inf_cls_name = [inf_cls_name[i] for i in idx_sort]\n",
    "# probs_max = probs_max[idx_sort]\n",
    "\n",
    "# print(\"Plotting...\")\n",
    "\n",
    "# # Plot image grid of \"input\" tensor with the predicted class and probability above each image\n",
    "# grid = torchvision.utils.make_grid(denormalize(imgs), nrow=30).permute(1, 2, 0).numpy()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(100, 100))\n",
    "# ax.imshow(grid)\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "\n",
    "# for i, (cls, prob) in enumerate(zip(inf_cls_name, probs_max)):\n",
    "#     ax.text(\n",
    "#         i % 30 * 384 + 384 // 2,\n",
    "#         i // 30 * 384 + 384 // 2,\n",
    "#         f\"{cls} ({prob*100:.1f}%)\",\n",
    "#         color=\"black\",\n",
    "#         fontsize=16,\n",
    "#         # Background color; semi-transparent white\n",
    "#         fontdict={\"family\": \"monospace\", \"weight\": \"bold\"},\n",
    "#         bbox=dict(facecolor=\"white\", alpha=0.5, pad=4, edgecolor=\"none\"),\n",
    "#         horizontalalignment=\"center\",\n",
    "#         verticalalignment=\"center\",\n",
    "#     )\n",
    "\n",
    "# print(\"Plotting done!\")\n",
    "\n",
    "# print(\"Rendering...\")\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# print(\"Rendering done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del logits, probs, inf_cls, probs_max, inf_cls_name, idx_sort, idx_sort_subset, random_indices, grid, fig, ax\n",
    "# del many_inputs, imgs, input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Memory usage: 15.08 / 15.65 GB'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "mem_info = [i / 10**9 for i in torch.cuda.mem_get_info(device)]\n",
    "\"Memory usage: {:.2f} / {:.2f} GB\".format(*mem_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_dir(paths, dst_dir, client: \"IOHandler\", verbose=False):\n",
    "    # Template: mget -d -O sftp://io.erda.au.dk:/AMI_GBIF_Pretraining_Data/NEW_SUPER_DIRECTORY ./PATH_TO_IMAGES\n",
    "    # The template above is used to copy a file from one location on the remote server to another location on the remote server,\n",
    "    # while preserving the directory structure of the source location and automatically creating the necessary subdirectories in the destination location.\n",
    "\n",
    "    cmd_prefix = \"mget -d -O sftp://io.erda.au.dk:/AMI_GBIF_Pretraining_Data/\"\n",
    "\n",
    "    cmd_suffix = []\n",
    "    for path in paths:\n",
    "        cmd_suffix.append(f\"./{path}\")\n",
    "    \n",
    "    cmd_suffix = \" \".join(cmd_suffix)\n",
    "\n",
    "    cmd = f\"{cmd_prefix}{dst_dir} {cmd_suffix}\"\n",
    "    if verbose:\n",
    "        print(\"Executing command:\", cmd)\n",
    "    result = client.execute_command(cmd, blocking=True, execute=True)\n",
    "    if verbose:\n",
    "        print(\"Result:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer min fill: 51, max fill: 76\n",
      "Producer thread started.\n",
      "Consumer thread started.\n",
      "Consumer thread started.\n",
      "Consumer thread started.\n",
      "Consumer thread started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a599e79594540cfabfd468831e83668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80309 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4ba2e5c60114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mpcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mQC_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mNOT_Larvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"Larvae\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a log file to ensure that the process can be restored if it is interrupted or an error occurs\n",
    "assert os.path.isdir(\"logs\"), RuntimeError(\"Log directory does not exist\")\n",
    "\n",
    "# Manual way\n",
    "log_files = os.listdir(\"logs\")\n",
    "log_files = [i for i in log_files if i.endswith(\".log\")]\n",
    "log_files = [i for i in log_files if i.startswith(model_name)]\n",
    "this_log_file = f\"{model_name}_{len(log_files)}.log\"\n",
    "\n",
    "\n",
    "with open(f\"logs/{this_log_file}\", \"w\") as f:\n",
    "    f.write(\"\")\n",
    "    for i, (input, label, path) in tqdm(enumerate(dataloader), leave = True, total=len(dataloader)):\n",
    "        try:\n",
    "            pred = model(input).argmax(dim=1).cpu()\n",
    "            pcls = [QC_dict[i.item()] for i in pred]\n",
    "            NOT_Larvae = [p for p, c in zip(path, pcls) if c != \"Larvae\"]\n",
    "            if len(NOT_Larvae) > 0:\n",
    "                move_to_dir(NOT_Larvae, \"without_larvae\", backend)\n",
    "            if i % 100 == 0:\n",
    "                f.write(f\"Batch {i} completed. {len(NOT_Larvae)} images moved to 'without_larvae'.\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error at batch {i}: {e}\")\n",
    "            f.write(f\"Error at batch {i}: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
